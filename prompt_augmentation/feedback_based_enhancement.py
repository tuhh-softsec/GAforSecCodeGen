import google.generativeai as genai
from typing import List
from .abs_prompt_augmentation import AbstractPromptAugmentation
import os
from dotenv import load_dotenv
import json
import random
from config import config


class FeedbackBasedEnhancement(AbstractPromptAugmentation):
    def __init__(self):
        super().__init__()
        load_dotenv()
        genai.configure(api_key=os.getenv('GEMINI_API_Key'))
        self.model = genai.GenerativeModel('gemini-pro')

    def extract_bandit_warnings(self, filepath: str) -> List[str]:
        with open(filepath, 'r') as file:
            data = json.load(file)
        warnings_per_file = []
        # extract the issue_text from the results as the warnings
        if data['results']:
            for result in data['results']:
                warnings_per_file.append(result['issue_text'])
        return warnings_per_file

    def select_n_warnings(self, warnings: List[str], num_warnings: int) -> List[str]:
        # remove duplicate warnings
        warnings = list(set(warnings))
        if len(warnings) < num_warnings:
            return warnings
        # select random n warnings
        return random.sample(warnings, num_warnings)

    def augment_prompt(self, prompt: str, iteration: int, num_variations: int = 4) -> List[str]:
        all_warnings = []
        # read bandit results in the directory that starts with the iteration number
        for file in os.listdir(config.bandit_output_dir):
            if file.startswith(str(iteration)):
                bandit_results = self.extract_bandit_warnings(
                    f"{config.bandit_output_dir}/{file}")
                warnings = self.extract_bandit_warnings(bandit_results)
                all_warnings.extend(warnings)
        # select n random warnings
        if all_warnings:
            selected_warnings = self.select_n_warnings(
                all_warnings, num_variations)
        else:
            selected_warnings = []

        if selected_warnings:
            instruction = (f"Rewrite the CODE_GENERATION_PROMPT by incorporating the "
                           f"SECURITY_WARNINGS generated by a SAST tool while evaluating "
                           f"the code generated using these prompts.\n"
                           f"CODE_GENERATION_PROMPT: {prompt}\n"
                           f"SECURITY_WARNINGS: {selected_warnings}")

            post_prompt = "Modified CODE_GENERATION_PROMPT: "

            input_text = f"{instruction} \n{post_prompt} "

            print("\nInput text sent to model:")
            print(input_text)
            print("\n" + "="*50 + "\n")

            # Generate variations sequentially instead of all at once
            variations = []
            for _ in range(num_variations):
                response = self.model.generate_content(
                    input_text,
                    generation_config={
                        'temperature': 0.7,
                    },
                    safety_settings={
                        "HARM_CATEGORY_DANGEROUS_CONTENT": "BLOCK_NONE",
                        "HARM_CATEGORY_HATE_SPEECH": "BLOCK_NONE",
                        "HARM_CATEGORY_HARASSMENT": "BLOCK_NONE",
                        "HARM_CATEGORY_SEXUALLY_EXPLICIT": "BLOCK_NONE"
                    }
                )
                variations.append(response.text)

            return variations
        else:
            return [prompt]


def main():
    augmenter = SecurityPromptAugmenter()

    test_prompt = """Generate secure python code for the given task description: """

    variations = augmenter.augment_prompt(test_prompt)

    print("Raw model outputs:")
    print("=" * 50)
    for i, variation in enumerate(variations, 1):
        print(f"\nOutput {i}:")
        print("-" * 30)
        print(variation)
        print("-" * 30)


if __name__ == "__main__":
    main()
